{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from micronet import MLP, Layer\n",
    "from micronet.activations import relu, softmax\n",
    "from micronet.losses import cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons, make_blobs\n",
    "x, y = make_moons(n_samples=100, noise=0.1)\n",
    "y = np.array([[1,0] if v == 0 else [0,1] for v in y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP([\n",
    "    Layer(2, 16, relu),\n",
    "    Layer(16, 16, relu),\n",
    "    Layer(16, 2, softmax),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Avg Loss 0.04493362630942085\n",
      "Epoch 1: Avg Loss 0.039444233664737635\n",
      "Epoch 2: Avg Loss 0.03844105568215489\n",
      "Epoch 3: Avg Loss 0.03763868713051245\n",
      "Epoch 4: Avg Loss 0.0369129510410726\n",
      "Epoch 5: Avg Loss 0.03622303768976235\n",
      "Epoch 6: Avg Loss 0.03565387368297143\n",
      "Epoch 7: Avg Loss 0.0351053746554969\n",
      "Epoch 8: Avg Loss 0.03470347040186908\n",
      "Epoch 9: Avg Loss 0.03430642825916766\n",
      "Epoch 10: Avg Loss 0.03392954833427239\n",
      "Epoch 11: Avg Loss 0.033682681099041094\n",
      "Epoch 12: Avg Loss 0.03340588664563794\n",
      "Epoch 13: Avg Loss 0.03312388820976554\n",
      "Epoch 14: Avg Loss 0.032938311857405776\n",
      "Epoch 15: Avg Loss 0.032699100382894516\n",
      "Epoch 16: Avg Loss 0.032563495668390896\n",
      "Epoch 17: Avg Loss 0.032361303459539366\n",
      "Epoch 18: Avg Loss 0.03223087854527251\n",
      "Epoch 19: Avg Loss 0.032031272025861174\n",
      "Epoch 20: Avg Loss 0.03191292608185736\n",
      "Epoch 21: Avg Loss 0.03172730151902035\n",
      "Epoch 22: Avg Loss 0.031628471279033774\n",
      "Epoch 23: Avg Loss 0.0314477510971336\n",
      "Epoch 24: Avg Loss 0.03134789656542322\n",
      "Epoch 25: Avg Loss 0.031189347464866304\n",
      "Epoch 26: Avg Loss 0.031006953485003878\n",
      "Epoch 27: Avg Loss 0.030909861815791383\n",
      "Epoch 28: Avg Loss 0.030752361145548607\n",
      "Epoch 29: Avg Loss 0.03062834928265658\n",
      "Epoch 30: Avg Loss 0.030513407975913738\n",
      "Epoch 31: Avg Loss 0.03039785598350201\n",
      "Epoch 32: Avg Loss 0.03028344556139357\n",
      "Epoch 33: Avg Loss 0.030191980420316438\n",
      "Epoch 34: Avg Loss 0.030102531799842444\n",
      "Epoch 35: Avg Loss 0.03001245619141373\n",
      "Epoch 36: Avg Loss 0.02991411257232791\n",
      "Epoch 37: Avg Loss 0.02985308820843817\n",
      "Epoch 38: Avg Loss 0.029714245721820437\n",
      "Epoch 39: Avg Loss 0.02961673601784259\n",
      "Epoch 40: Avg Loss 0.029517092106498194\n",
      "Epoch 41: Avg Loss 0.029462305561075652\n",
      "Epoch 42: Avg Loss 0.0293309027579952\n",
      "Epoch 43: Avg Loss 0.02923991890454339\n",
      "Epoch 44: Avg Loss 0.02916021635825995\n",
      "Epoch 45: Avg Loss 0.029113047889101032\n",
      "Epoch 46: Avg Loss 0.028996900854970392\n",
      "Epoch 47: Avg Loss 0.02891866698917695\n",
      "Epoch 48: Avg Loss 0.0288392821036611\n",
      "Epoch 49: Avg Loss 0.028758709478260494\n",
      "Epoch 50: Avg Loss 0.028678581832461535\n",
      "Epoch 51: Avg Loss 0.028598854894576104\n",
      "Epoch 52: Avg Loss 0.02851999212045951\n",
      "Epoch 53: Avg Loss 0.028441656911658654\n",
      "Epoch 54: Avg Loss 0.028369491134618847\n",
      "Epoch 55: Avg Loss 0.02828668304107055\n",
      "Epoch 56: Avg Loss 0.0282142669333811\n",
      "Epoch 57: Avg Loss 0.028126993906874072\n",
      "Epoch 58: Avg Loss 0.0280461176078365\n",
      "Epoch 59: Avg Loss 0.02797382763372084\n",
      "Epoch 60: Avg Loss 0.02786885876293812\n",
      "Epoch 61: Avg Loss 0.02778965212575917\n",
      "Epoch 62: Avg Loss 0.027696650541736676\n",
      "Epoch 63: Avg Loss 0.027605937391056778\n",
      "Epoch 64: Avg Loss 0.027508894176793627\n",
      "Epoch 65: Avg Loss 0.02742980387199894\n",
      "Epoch 66: Avg Loss 0.027338732493172493\n",
      "Epoch 67: Avg Loss 0.027242190349865622\n",
      "Epoch 68: Avg Loss 0.027157839886285787\n",
      "Epoch 69: Avg Loss 0.027043258137409106\n",
      "Epoch 70: Avg Loss 0.026939462396248025\n",
      "Epoch 71: Avg Loss 0.026836169205687627\n",
      "Epoch 72: Avg Loss 0.02673364093898473\n",
      "Epoch 73: Avg Loss 0.026636648038075333\n",
      "Epoch 74: Avg Loss 0.026529970174050135\n",
      "Epoch 75: Avg Loss 0.026430577534432675\n",
      "Epoch 76: Avg Loss 0.026331175637502726\n",
      "Epoch 77: Avg Loss 0.02623223273069196\n",
      "Epoch 78: Avg Loss 0.026128193243186465\n",
      "Epoch 79: Avg Loss 0.026030578354338835\n",
      "Epoch 80: Avg Loss 0.025935525293916045\n",
      "Epoch 81: Avg Loss 0.025844166857766623\n",
      "Epoch 82: Avg Loss 0.025755654294782042\n",
      "Epoch 83: Avg Loss 0.025665886760389327\n",
      "Epoch 84: Avg Loss 0.025576715216716076\n",
      "Epoch 85: Avg Loss 0.025489666372579906\n",
      "Epoch 86: Avg Loss 0.02540135246016037\n",
      "Epoch 87: Avg Loss 0.025318320308766917\n",
      "Epoch 88: Avg Loss 0.025230028358349504\n",
      "Epoch 89: Avg Loss 0.025140664173992827\n",
      "Epoch 90: Avg Loss 0.025055566963935398\n",
      "Epoch 91: Avg Loss 0.024967306384858376\n",
      "Epoch 92: Avg Loss 0.024879440783311224\n",
      "Epoch 93: Avg Loss 0.02479213507581894\n",
      "Epoch 94: Avg Loss 0.024705701479455583\n",
      "Epoch 95: Avg Loss 0.02462050052209966\n",
      "Epoch 96: Avg Loss 0.02452675031513475\n",
      "Epoch 97: Avg Loss 0.02444084748832252\n",
      "Epoch 98: Avg Loss 0.024351702605267977\n",
      "Epoch 99: Avg Loss 0.024266528168157525\n"
     ]
    }
   ],
   "source": [
    "model.train(x, y, loss=cross_entropy, epochs=100, batch_size=30, learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: [0.192 0.808], Actual: [0 1]\n",
      "Prediction: [0.924 0.076], Actual: [1 0]\n",
      "Prediction: [0. 1.], Actual: [0 1]\n",
      "Prediction: [1. 0.], Actual: [1 0]\n",
      "Prediction: [0.999 0.001], Actual: [1 0]\n",
      "Prediction: [0.999 0.001], Actual: [1 0]\n",
      "Prediction: [0. 1.], Actual: [0 1]\n",
      "Prediction: [1. 0.], Actual: [1 0]\n",
      "Prediction: [0.554 0.446], Actual: [0 1]\n",
      "Prediction: [0.646 0.354], Actual: [1 0]\n",
      "Prediction: [0. 1.], Actual: [0 1]\n",
      "Prediction: [0.054 0.946], Actual: [0 1]\n",
      "Prediction: [0.066 0.934], Actual: [0 1]\n",
      "Prediction: [1. 0.], Actual: [1 0]\n",
      "Prediction: [0.797 0.203], Actual: [1 0]\n",
      "Prediction: [0. 1.], Actual: [0 1]\n",
      "Prediction: [0.192 0.808], Actual: [0 1]\n",
      "Prediction: [0.999 0.001], Actual: [1 0]\n",
      "Prediction: [0. 1.], Actual: [0 1]\n",
      "Prediction: [0.04 0.96], Actual: [0 1]\n",
      "Prediction: [0.998 0.002], Actual: [1 0]\n",
      "Prediction: [0.864 0.136], Actual: [1 0]\n",
      "Prediction: [0.898 0.102], Actual: [1 0]\n",
      "Prediction: [1. 0.], Actual: [1 0]\n",
      "Prediction: [0.239 0.761], Actual: [0 1]\n",
      "Prediction: [0.856 0.144], Actual: [1 0]\n",
      "Prediction: [0.874 0.126], Actual: [1 0]\n",
      "Prediction: [0.959 0.041], Actual: [1 0]\n",
      "Prediction: [1. 0.], Actual: [1 0]\n",
      "Prediction: [0. 1.], Actual: [0 1]\n",
      "Prediction: [1. 0.], Actual: [1 0]\n",
      "Prediction: [0.877 0.123], Actual: [1 0]\n",
      "Prediction: [0.876 0.124], Actual: [1 0]\n",
      "Prediction: [0.983 0.017], Actual: [1 0]\n",
      "Prediction: [0.177 0.823], Actual: [0 1]\n",
      "Prediction: [0.999 0.001], Actual: [1 0]\n",
      "Prediction: [0.155 0.845], Actual: [0 1]\n",
      "Prediction: [1. 0.], Actual: [1 0]\n",
      "Prediction: [0. 1.], Actual: [0 1]\n",
      "Prediction: [0.338 0.662], Actual: [0 1]\n",
      "Prediction: [0.023 0.977], Actual: [0 1]\n",
      "Prediction: [0.912 0.088], Actual: [1 0]\n",
      "Prediction: [0.021 0.979], Actual: [0 1]\n",
      "Prediction: [0.006 0.994], Actual: [0 1]\n",
      "Prediction: [0. 1.], Actual: [0 1]\n",
      "Prediction: [0.061 0.939], Actual: [0 1]\n",
      "Prediction: [0.449 0.551], Actual: [1 0]\n",
      "Prediction: [0.845 0.155], Actual: [1 0]\n",
      "Prediction: [1. 0.], Actual: [1 0]\n",
      "Prediction: [0.498 0.502], Actual: [0 1]\n",
      "Prediction: [0.007 0.993], Actual: [0 1]\n",
      "Prediction: [0. 1.], Actual: [0 1]\n",
      "Prediction: [0.594 0.406], Actual: [1 0]\n",
      "Prediction: [0.998 0.002], Actual: [1 0]\n",
      "Prediction: [0. 1.], Actual: [0 1]\n",
      "Prediction: [0.867 0.133], Actual: [1 0]\n",
      "Prediction: [0.999 0.001], Actual: [1 0]\n",
      "Prediction: [0.043 0.957], Actual: [0 1]\n",
      "Prediction: [0.937 0.063], Actual: [1 0]\n",
      "Prediction: [0.086 0.914], Actual: [0 1]\n",
      "Prediction: [0.462 0.538], Actual: [0 1]\n",
      "Prediction: [0.012 0.988], Actual: [0 1]\n",
      "Prediction: [0.348 0.652], Actual: [0 1]\n",
      "Prediction: [0.886 0.114], Actual: [1 0]\n",
      "Prediction: [0.007 0.993], Actual: [0 1]\n",
      "Prediction: [0.001 0.999], Actual: [0 1]\n",
      "Prediction: [0.108 0.892], Actual: [1 0]\n",
      "Prediction: [0.999 0.001], Actual: [1 0]\n",
      "Prediction: [0.056 0.944], Actual: [0 1]\n",
      "Prediction: [0.057 0.943], Actual: [0 1]\n",
      "Prediction: [0.915 0.085], Actual: [1 0]\n",
      "Prediction: [0.023 0.977], Actual: [0 1]\n",
      "Prediction: [0.945 0.055], Actual: [1 0]\n",
      "Prediction: [0.121 0.879], Actual: [0 1]\n",
      "Prediction: [0. 1.], Actual: [0 1]\n",
      "Prediction: [0.007 0.993], Actual: [0 1]\n",
      "Prediction: [0. 1.], Actual: [0 1]\n",
      "Prediction: [0. 1.], Actual: [0 1]\n",
      "Prediction: [0.917 0.083], Actual: [1 0]\n",
      "Prediction: [1. 0.], Actual: [1 0]\n",
      "Prediction: [0.998 0.002], Actual: [1 0]\n",
      "Prediction: [1. 0.], Actual: [1 0]\n",
      "Prediction: [0.232 0.768], Actual: [0 1]\n",
      "Prediction: [0.006 0.994], Actual: [0 1]\n",
      "Prediction: [0.001 0.999], Actual: [0 1]\n",
      "Prediction: [0.832 0.168], Actual: [1 0]\n",
      "Prediction: [0.849 0.151], Actual: [1 0]\n",
      "Prediction: [0. 1.], Actual: [0 1]\n",
      "Prediction: [0. 1.], Actual: [0 1]\n",
      "Prediction: [0.492 0.508], Actual: [1 0]\n",
      "Prediction: [0.606 0.394], Actual: [0 1]\n",
      "Prediction: [0.998 0.002], Actual: [1 0]\n",
      "Prediction: [0.032 0.968], Actual: [0 1]\n",
      "Prediction: [0.076 0.924], Actual: [0 1]\n",
      "Prediction: [0.997 0.003], Actual: [1 0]\n",
      "Prediction: [0.285 0.715], Actual: [1 0]\n",
      "Prediction: [1. 0.], Actual: [1 0]\n",
      "Prediction: [0.574 0.426], Actual: [1 0]\n",
      "Prediction: [1. 0.], Actual: [1 0]\n",
      "Prediction: [0.26 0.74], Actual: [0 1]\n"
     ]
    }
   ],
   "source": [
    "for prediction, actual in zip(map(model, x), y):\n",
    "    print(f\"Prediction: {prediction.round(3)}, Actual: {actual}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
